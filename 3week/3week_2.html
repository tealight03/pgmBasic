<html>
    <title>프로그래밍 기초 3주차 과제(2)</title>
    <head></head>
    <body>
        <ul>
            <li>
                <b>서버-소켓 구조</b>
                <p>
                    서버-소켓 구조는 서버에서 실행되는 프로그램이 클라이언트 소켓의 요청을 받아들이고 응답을 보내기 위해 소켓을 사용하는 것을 말한다. 
                    <br>서버-소켓 구조에서 소켓은 서버 프로그램과 클라이언트 프로그램 간의 통신을 위한 통로로, 클라이언트 측에서의 접속 대기를 위한 소켓이다. 
                    <br>클라이언트가 서버 소켓에 접속 요청을 하면, 서버 소켓은 클라이언트의 연결 요청을 받아들이고 
                    <br>클라이언트 소켓을 생성해서 서버 소켓과 연결하는 방식으로 서로 통신할 수 있다.
                </p>
            </li>
            <hr>
            <li>
                <b>클라이언트-소켓 구조</b>
                <p>
                    클라이언트-소켓 구조는 클라이언트에서 실행되는 프로그램이 서버 소켓에 요청을 보내고 서버로부터 응답을 받기 위해 소켓을 사용하는 것을 말한다. 
                    <br>클라이언트-소켓 구조에서 클라이언트 소켓은 서버로 접속하는 소켓으로, 클라이언트가 서버에 접속 요청을 보내면, 서버 소켓은 해당 요청에 응답하여 클라이언트 소켓과 연결되고
                    <br>클라이언트가 클라이언트 소켓을 통해 서버에 요청을 보내고, 서버는 클라이언트 소켓을 통해 클라이언트에게 응답을 보내는 방식으로 통신 시 사용된다. 
                </p>
            </li>
            <hr>
            <li>
                <b>파일 디스크립터(소켓)</b>
                <p>
                    파일 디스크립터(file discripter)는 파일이나 소켓과 같은 입출력 장치에 대한 액세스 권한을 부여하는 숫자를 말한다. 
                    <br>운영 체제에 의해 관리되며, 프로세스가 파일이나 소켓에 액세스하려면 먼저 파일 디스크립터를 얻어야 한다.
                    <br>파일 디스크립터는 프로세스가 파일이나 소켓에 액세스하는 데 사용되고, 이를 이용해 파일을 열고, 읽고, 쓰고, 닫을 수 있다.
                    <br>또한 소켓을 연결하여 데이터 전송 및 통신, 연결 단절의 작업을 실행할 수도 있다. 
                    <br>프로세스가 파일이나 소켓에 액세스하는 데 필수적인 요소로 파일 디스크립터가 없다면 프로세스는 파일이나 소켓에 액세스할 수 없다. 
                    <br>소켓은 프로세스 간에 데이터를 주고받기 위한 통신 채널로, TCP 소켓과 UDP 소켓으로 구분된다.
                    <br>TCP 소켓은 결과를 신뢰할 수 있는 통신을 제공하며, UDP 소켓은 결과를 신뢰할 수 없는 통신을 제공한다. 
                </p>
            </li>
            <hr>
            <li>
                <b>http 요청(+헤더) 과 응답(+헤더)</b>
                <p>
                    HTTP(Hypertext Transfer Protocol)는 인터넷 상에서 데이터를 주고받을 때 사용되는 프로토콜이다. 
                    <br>클라이언트-서버 모델에서 클라이언트와 서버는 HTTP Request와 HTTP Response로 서로 통신한다. 
                    <br>HTTP Request는 클라이언트 측에서 서버에게 이런이런 자료가 필요한데, 혹시 있어? 라고 메시지를 보내 데이터를 '요청'하는 것이다.
                    <br>클라이언트가 보내는 HTTP Request에는 HTTP 메소드(GET, POST), 요청 URL, HTTP 버전이 담긴 Request Line,
                    <br>클라이언트가 서버에게 전달하는 정보를 포함한 Headers, HTTP 요청에 포함되는 데이터인 Body가 포함되어있다. 
                    <br>이렇게 클라이언트가 서버에게 요청 메시지를 보내면
                    <br>서버 측에서는 이 요청 메시지를 확인해 HTTP Response를 클라이언트에게 보내서 
                    <br>클라이언트가 요청한 파일의 존재 여부 등을 알려준다. 
                    <br>HTTP Response에는 HTTP 버전, 상태 코드, 상태 메세지를 포함한 Status Line,
                    <br>서버가 클라이언트에게 전달하는 정보를 포함한 Headers, 서버가 클라이언트에게 보내는 데이터가 담긴 Body가 포함되어있다.
                    <br>참고로 Request와 Response 모두에 포함되는 Headers는 이를 통해 클라이언트와 서버가 서로 정보를 전달하고, 
                    <br>HTTP 요청과 응답의 내용 및 처리 방식을 설정할 수 있으므로 이 프로토콜에서 핵심적인 내용이라고 할 수 있다. 
                    <br>+) 캐시 제어, 인증, 페이지 갱신 등 HTTP 프로토콜의 다양한 기능이 HTTP 헤더를 통해서 구현된다.
                </p>
            </li>
            <hr>
            <li>
                <b>스트레스 테스트</b>
                <p>
                    서버 스트레스 테스트란, 서버가 참여자 수가 증가하여 더 많은 트래픽을 처리할 때 안정성 및 성능을 확인하는 과정을 말한다.
                    <br>서버에 접속한 유저가 증가하면 서버의 프로세스 처리 능력은 저하하게 되는데
                    <br>이렇게 접속 유저가 급증해 서버에 무리가 가는 수준이 어느 정도인지,
                    <br>이런 상황일 때 어떤 조치를 취해주면 서버가 안정화되는지 등을 파악하기 위해 테스트를 진행한다. 
                    <br>사람으로 치자면 예방접종 맞히는 그런 느낌..?
                    <br>Load Testing, Stress Testing, Soak Testing 등의 다양한 방법으로 테스트할 수 있고
                    <br>보통 서버 과부하를 유발하여 지속적으로 스트레스를 주고 서버의 반응 상태를 관찰하는 것이 일반적인 방식이다. 
                    <br>Load Testing은 시스템이 일정 수준 이상의 처리 능력을 유지할 수 있는지 테스트하는 방법으로,
                    <br>대규모 트래픽이 발생하는 웹 사이트에서의 부하 테스트가 이에 해당하고
                    <br>Stress Testing은 시스템이 한계치에 다다를 때까지 어떤 식으로든 대응을 할 수 있는지 테스트하는 방식으로,
                    <br>사용자가 엄청나게 많은 입력을 한 경우에 시스템이 이에 대비하는 것을 테스트하는 방법이 해당한다. 
                    <br>마지막으로 Soak Testing은 장시간에 걸쳐 지속적으로 부하를 가했을 때 
                    <br>시스템이 얼마나 오래 작동할 수 있는지 테스트하는 방식이다. 
                    <br>이 중 Load Testing과 Stress Testing 방법이 가장 자주 사용되는 방법이다. 
                </p>
            </li>
            <hr>
            <li>
                <b>시스템 쓰레드</b>
                <p>
                    우리는 프로그램의 응답성 향상, 자원 공유, 멀티태스킹을 위해 쓰레드를 사용하는데, 쓰레드 중 
                    <br>시스템 쓰레드(System Thread)는 운영체제가 제공하는 쓰레드로, 사용자 수준 쓰레드와는 달리 자원을 할당 받을 수 있는 단위가 운영체제로부터 할당받는 쓰레드이다. 
                    <br>시스템 쓰레드는 커널 모드에서 작동하기 때문에 작업은 운영체제 자체에서 수행하며 이 쓰레드는 하드웨어나 다른 시스템 리소스를 사용할 수도 있다.
                    <br>따라서 시스템 쓰레드는 I/O 작업과 같은 커널 모드 수행이 필요한 작업에서 주로 사용되고,
                    <br>사용자 쓰레드와 달리 스케줄링을 제어하거나 우선순위를 변경할 수는 없지만 운영체제의 스케줄러에 의해 관리되며 운영체제에서 제공하는 API를 사용하여 작업이 수행된다.
                </p>
            </li>
            <hr>
            <li>
                <b>블로킹과 논블로킹</b>
                <p>
                    블로킹과 논블로킹은 시스템의 프로그램 처리 방식에 대한 개념이다. 
                    <br>블로킹은 한 작업이 끝날 때까지 다른 작업을 수행하지 않는 방식으로, 사용이 간단하고 프로그래밍이 쉽다는 장점을 보유하고 있고
                    <br>작업의 순서와 안정성을 보장할 수 있지만 작업 처리 시간이 오래 걸리면 전체 시스템의 속도를 늦추게 될 수 있다. 
                    <br>다른 작업을 중지시켜야 하므로 효율성이 굉장히 떨어진다고 볼 수 있다. 
                    <br>반면 논블로킹은 한 작업이 수행 완료되지 않아도 다른 작업을 수행할 수 있는 방식으로
                    <br>다른 작업으로 전환되면, 이전 작업은 일시 중단한 채 해당 작업을 이어나가게 된다. 
                    <br>블로킹보다 더 효율적인 방식으로 작업을 처리할 수 있지만, 작업의 순서와 안정성은 보장할 수 없다. 
                    <br>이 방식은 전체적인 시스템 성능과 효율성은 향상되지만, 프로그래밍이 복잡해질 수 있다는 단점이 있다. 
                    <br>입출력 작업이 완료되지 않더라도 다른 작업을 처리할 수 있도록 하기 위해 입출력 작업의 결과를 처리할 별도의 코드가 필요하기 때문이다. 
                    <br>블로킹과 논블로킹의 차이점은 위에 설명했듯이 I/O 작업을 어떻게 처리하느냐에 있다.
                    <br>블로킹은 파일을 읽는 I/O 작업이 블로킹 방식으로 수행될 때 파일이 모두 읽히기 전에는 해당 프로세스나 스레드는 대기하고 있어야하기 때문에
                    <br>해당 작업이 완료될 때까지 다른 작업을 수행할 수 없어서 성능 문제가 발생할 수 있고,
                    <br>논블로킹은 I/O 작업이 완료되지 않아도 다른 작업을 수행할 수 있는 작업 처리 방식이기 때문에
                    <br>파일을 읽는 I/O 작업이 논블로킹 방식으로 수행될 경우 해당 작업이 완료될 때까지 대기하지 않고 다른 작업을 수행할 수 있어서
                    <br>단일 프로세스나 스레드에서 여러 I/O 작업을 관리할 수 있으며, 성능 문제가 발생할 가능성을 줄일 수 있다는 장점을 갖게 된다. 
                </p>
            </li>
            <hr>
            <li>
                <b>로드 밸런싱</b>
                <p>
                    로드 밸런싱은 여러 대의 서버에 부하를 고르게 분산시켜서 성능을 향상시키는 기술이다. 
                    <br>주로 대규모 트래픽이 발생하는 웹 서비스나 애플리케이션에서 서버 부하 분산을 통해 서버의 성능, 가용성 및 안정성을 높이는 데 주로 사용된다. 
                    <br>클라이언트 요청의 양이 많거나 대용량 파일을 다운로드하는 등의 부하가 발생할 경우 하나의 서버로는 처리할 수 없는 상황이 발생할 수도 있는데,
                    <br>이때 로드 밸런서를 사용해 부하가 많은 서버는 다른 서버로 요청을 전달하고 전체 시스템의 안정성을 높이고 성능 문제를 해결하여
                    <br>분배된 요청을 받은 각 서버가 고르게 일을 처리할 수 있도록 할 수 있다. 로드 밸런서를 이용하면 시스템의 안정성과 가용성을 높이면서 서버의 성능을 최적화할 수도 있다. 
                    <br>또한 서버의 추가/제거 작업도 간편해지기 때문에 시스템 유지보수나 확장도 용이해진다. 
                    <br>로드 밸런서의 핵심적인 동작 원리는 클라이언트로부터의 요청을 서버로 분산시켜주는 것이다. 
                    <br>클라이언트가 로드 밸런서에 요청을 보내면 로드 밸런서는 미리 설정된 로드 밸런싱 알고리즘을 바탕으로 
                    <br>해당 요청을 처리할 가장 적절한 서버를 선택하여 각 서버에 부하된 요청들을 분산시킨다. 
                    <br>로드 밸런싱 알고리즘에는 여러 종류가 있으며 대표적인 것으로는 라운드 로빈, 가중 라운드 로빈, IP 해싱, 
                    <br>최소 연결, 최소 응답시간, 최소 대기시간 등이 있는데 서비스의 특성에 따라 선택되는 알고리즘이 달라진다. 
                    <br>로드 밸런서는 일반적으로 하드웨어, 소프트웨어, 클라우드 서비스 등으로 제공되는데
                    <br>각각의 방식에 따라 구성 방법이 다르지만 공통적으로 백엔드 서버의 IP 주소와 포트번호, 로드 밸런싱 알고리즘, 세션 관리 방식 등을 설정해줘야 한다. 
                </p>
            </li>
            <hr>
            <li>
                <b>HTTP1.0과 1.1</b> 
                <p>
                    HTTP 1.0과 1.1 모두 현재 웹에서 가장 많이 사용하는 HTTP 프로토콜 버전이다. 
                    <br>HTTP 1.0은 초창기 HTTP 프로토콜로, 이 버전에서는 HTTP 요청과 응답이 한 번 이루어지면 TCP 연결이 바로 끊어지는 것 때문에
                    <br>웹페이지의 크기가 크거나 많은 파일을 다운로드하는 경우 매번 연결을 새롭게 열고 닫아야 하기 때문에 네트워크 속도가 늦어진다는 단점이 있다. 
                    <br>그래서 HTTP 1.1 버전에서는 HTTP 1.0의 이러한 문제점을 해결하기 위해 요청-응답 사이에 TCP 연결을 유지할 수 있도록 개선하여
                    <br>불필요한 연결 과정을 줄일 수 있어 속도가 훨씬 빨라졌고, 또한 HTTP 헤더에 압축 기능과 청크 전송 인코딩(Chunked Transfer Encoding) 기능도 추가되어
                    <br>전송할 데이터를 압축하거나 분할하여 보내는 방식을 이용하게 되어 네트워크 효율성도 높아졌다. 
                    <br>그러나 HTTP 1.0과 HTTP 1.1은 기능과 특징이 다르므로 호환성에 문제가 발생할 수도 있기 때문에
                    <br>HTTP 1.1이 기본 설정이 되어 있는 많은 서버에서는 HTTP 1.0 요청을 최대한 HTTP 1.1 요청과 비슷하게 처리하도록 설계하는 등
                    <br>이러한 호환성 문제를 해결하기 위해 몇 가지 구축이 되어 있다. 
                    <br>HTTP 1.0과 HTTP 1.1의 가장 큰 차이점은 지속 커넥션(persistent connection)과 파이프라인(pipeline) 지원 여부라고 할 수 있다. 
                    <br>HTTP 1.0은 기본적으로 요청과 응답 각각에 대한 연결(connection)을 매번 새롭게 열고 닫아야 했기 때문에
                    <br>매 요청마다 연결 과정을 반복하는 오버헤드가 발생하는 반면, HTTP 1.1은 요청과 응답 각각에 대한 지속 커넥션을 지원하기 때문에
                    <br>매번 새로 연결할 필요가 없어서 기존 버전 대비 웹 서버와 클라이언트 간의 통신 속도를 대폭 향상되었다. 
                    <br>또한 HTTP 1.1은 클라이언트가 여러 개의 HTTP 요청을 동시에 보낼 수 있도록 허용해 서버의 응답 대기 시간을 대폭 단축시킬 수 있는
                    <br>파이프라인(pipeline) 방식도 지원하므로 HTTP 1.1을 이용하면 클라이언트는 요청 A, B, C를 직렬적으로 보내지 않고 동시에 보낼 수 있게 된다. 
                    <br>그리고 HTTP 1.1은 보안성을 개선하기 위해 SSL/TLS 암호화를 기본적으로 지원하기 때문에 1.1보다 훨씬 장점이 많다. 
                </p>
            </li> 
            <hr>
            <li>
                <b>HTTPS(SSL/TLS)</b>
                <p>
                    HTTPS(Hyper Text Transfer Protocol Secure)는 HTTP 프로토콜의 보안 강화 버전으로,
                    <br>SSL(Secure Sockets Layer) 또는 TLS(Transport Layer Security) 프로토콜을 이용해서
                    <br>암호화된 통신 채널을 생성하여 데이터를 보호하는 방식으로 동작한다. 
                    <br>HTTPS는 아래와 같은 방식으로 동작한다. 
                    <br>1. 클라이언트가 HTTPS로 암호화된 페이지에 접속하면 서버는 공개키(Public Key)를 클라이언트에게 제공
                    <br>2. 클라이언트는 공개키를 이용하여 세션키(Session Key)를 생성하고, 이 세션키를 이용하여 데이터를 암호화
                    <br>3. 암호화된 데이터를 서버에 전송하면, 서버는 이를 복호화하여 응답을 전송
                    <br>또한 HTTPS는 프라이버시 보호와 인증 등의 기능을 제공하여, 안전한 인터넷 사용 환경을 제공하는 데 큰 역할을 한다.
                    <br>HTTPS를 사용하면 해커가 데이터를 조작하거나 해킹하여 확인하기가 조금 어려워져서 보안이 탄탄해진다. 
                    <br>참고로 http로 페이지에 접속했을 때 -s를 붙여주면 임시로 https로 접근하게 되어
                    <br>일시적으로 보안이 강화된 상태에서 데이터를 주고받을 수 있게 된다.
                </p>
            </li>
        </ul>
    </body>
</html>